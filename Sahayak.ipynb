{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110156,"status":"ok","timestamp":1704287753813,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"gn-5vlV-DHSx","outputId":"3e1d2349-0cd6-4a2e-e798-954dfa024771"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q -U datasets scipy ipywidgets matplotlib einops"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"us3zvAk0DL3C","colab":{"base_uri":"https://localhost:8080/","height":494},"executionInfo":{"status":"error","timestamp":1704287760186,"user_tz":-330,"elapsed":6441,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}},"outputId":"a5548572-8a09-4f9b-b89f-78ea1344e223"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-aa996653a604>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_sharded_data_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFullOptimStateDictConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFullStateDictConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m fsdp_plugin = FullyShardedDataParallelPlugin(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstate_dict_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFullStateDictConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank0_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptim_state_dict_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFullOptimStateDictConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank0_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/dataclasses.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sharding_strategy, backward_prefetch, mixed_precision_policy, auto_wrap_policy, cpu_offload, ignored_modules, state_dict_type, state_dict_config, optim_state_dict_config, limit_all_gathers, use_orig_params, param_init_fn, sync_module_states, forward_prefetch, activation_checkpointing)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/dataclasses.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m   1010\u001b[0m                     \u001b[0;34m\"There are currently no available devices found, must be one of 'XPU', 'CUDA', or 'NPU'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 )\n","\u001b[0;31mRuntimeError\u001b[0m: There are currently no available devices found, must be one of 'XPU', 'CUDA', or 'NPU'."]}],"source":["from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287760187,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"K1s7W0h5Fbvu"},"outputs":[],"source":["!pip install -q wandb -U"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1704287761005,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"pdhVXDCFDUgh"},"outputs":[],"source":["import wandb, os\n","wandb.login()\n","\n","wandb_project = \"viggo-finetune\"\n","if len(wandb_project) > 0:\n","    os.environ[\"WANDB_PROJECT\"] = wandb_project"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1704287761005,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"ztI1MKgYAQsQ"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djl9YtSCEAMd","executionInfo":{"status":"aborted","timestamp":1704287761005,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["from datasets import load_dataset\n","\n","train_dataset = load_dataset('json', data_files='notes.jsonl', split='train')\n","eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVrbkxmvEYau","executionInfo":{"status":"aborted","timestamp":1704287761006,"user_tz":-330,"elapsed":10,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["def formatting_func(example):\n","    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"wu7UmUzIKBLN"},"outputs":[],"source":["!pip install einops"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"X0xx9FxCKvYf"},"outputs":[],"source":["!pip install torch\n","!pip install accelerate\n","!pip install -i https://test.pypi.org/simple/ bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"kkUzWV_mEme2"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","base_model_id = \"microsoft/phi-2\"\n","model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, load_in_8bit=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"Iny9TTRdHjOq"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    padding_side=\"left\",\n","    add_eos_token=True,\n","    add_bos_token=True,\n","    use_fast=False,\n",")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","def generate_and_tokenize_prompt(prompt):\n","    return tokenizer(formatting_func(prompt))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDPrgAqyH1sv","executionInfo":{"status":"aborted","timestamp":1704287761006,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"DWIG6qshIjTQ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n","    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n","    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n","    print(len(lengths))\n","\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n","    plt.xlabel('Length of input_ids')\n","    plt.ylabel('Frequency')\n","    plt.title('Distribution of Lengths of input_ids')\n","    plt.show()\n","\n","plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nf_lZN7KJQtm","executionInfo":{"status":"aborted","timestamp":1704287761006,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["max_length = 65 # This was an appropriate max length for my dataset\n","\n","def generate_and_tokenize_prompt2(prompt):\n","    result = tokenizer(\n","        formatting_func(prompt),\n","        truncation=True,\n","        max_length=max_length,\n","        padding=\"max_length\",\n","    )\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"naHC2aCWJU2t","executionInfo":{"status":"aborted","timestamp":1704287761006,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"dKuJvKP9JYVA"},"outputs":[],"source":["print(tokenized_train_dataset[1]['input_ids'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761006,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"4RYUYJoxJfAn"},"outputs":[],"source":["plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3A_hNrMJiyf","executionInfo":{"status":"aborted","timestamp":1704287761007,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["eval_prompt = \"\"\" What are the laws in India regarding drug use?\n","\n","\n","### Output:\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3idwbzXPJluM","executionInfo":{"status":"aborted","timestamp":1704287761007,"user_tz":-330,"elapsed":9,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["eval_prompt = \" India has strict laws against drug use and trafficking. The Narcotic Drugs and Psychotropic Substances Act, 1988, prohibits the cultivation, production, possession, sale, purchase, transportation, and use of narcotic drugs and psychotropic substances. Violations of this Act can lead to imprisonment and heavy fines. # \""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"NhBeotvzJpsW"},"outputs":[],"source":["from transformers import AutoTokenizer\n","base_model_id = \"microsoft/phi-2\"\n","eval_tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    add_bos_token=True,\n","    use_fast=False, # needed for now, should be fixed soon\n",")\n","\n","model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","model.eval()\n","with torch.no_grad():\n","    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UoPn6YyXJsZO","executionInfo":{"status":"aborted","timestamp":1704287761007,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"6HSrhVKYJvmH"},"outputs":[],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"YHWZoTFAJyqW"},"outputs":[],"source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"Wqkv\",\n","        \"fc1\",\n","        \"fc2\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"5pcr_SuXJyz1"},"outputs":[],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"QA5W2GHLXplI"},"outputs":[],"source":["!pip install git+https://github.com/huggingface/transformers.git@main accelerate\n","!pip install accelerate\n"]},{"cell_type":"code","source":["from accelerate import Accelerator\n","model = accelerator.prepare_model(model)\n"],"metadata":{"id":"4-gwkFbxc-ed","executionInfo":{"status":"aborted","timestamp":1704287761007,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHEFOsJCJ8S5","executionInfo":{"status":"aborted","timestamp":1704287761007,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["if torch.cuda.device_count() > 1: # If more than 1 GPU\n","    model.is_parallelizable = True\n","    model.model_parallel = True"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1704287761007,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"PePZ6cs3KBNn"},"outputs":[],"source":["import transformers\n","from datetime import datetime\n","\n","project = \"journal-finetune\"\n","base_model_name = \"phi2\"\n","run_name = base_model_name + \"-\" + project\n","output_dir = \"./\" + run_name\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    args=transformers.TrainingArguments(\n","        output_dir=output_dir,\n","        warmup_steps=1,\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        max_steps=500,\n","        learning_rate=2.5e-5, # Want a small lr for finetuning\n","        optim=\"paged_adamw_8bit\",\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=\"./logs\",        # Directory for storing logs\n","        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n","        do_eval=True,                # Perform evaluation at the end of training\n","        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n","        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761008,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"lTBPadkFKC_s"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","base_model_id = \"microsoft/phi-2\"\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,  # Phi2, same as before\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n",")\n","\n","eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n","eval_tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qbA2WvjKHed","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"outputs":[],"source":["from peft import PeftModel\n","\n","ft_model = PeftModel.from_pretrained(base_model, \"phi2-journal-finetune/checkpoint-500\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1704287761008,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"},"user_tz":-330},"id":"w12YDOQqKOq1"},"outputs":[],"source":["eval_prompt = \"  What are the laws in India regarding drug use? #  Output \"\n","model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","ft_model.eval()\n","with torch.no_grad():\n","    response = (eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.11)[0], skip_special_tokens=True))\n"]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"BfGRU5fTgZ-X","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the index of the last full stop in the generated text\n","last_full_stop_index = response.rfind('.')\n","\n","# Trim the text to include only up to the last full stop\n","trimmed_text = response[:last_full_stop_index + 1]\n","\n","# Print the final generated and trimmed response\n","print(trimmed_text)"],"metadata":{"id":"gY5x-uq8ofDj","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from getpass import getpass\n","# uplink_key = getpass('Enter your Uplink key: ')\n","\n","uplink_key = 'server_PLF6KCTD757TOLWGNTMBITNT-TFZXCF6MZDIJBBI6'"],"metadata":{"id":"FE6wQCZb218v","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install anvil-uplink"],"metadata":{"id":"AzgErNo3249n","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import anvil.server\n","anvil.server.connect('server_PLF6KCTD757TOLWGNTMBITNT-TFZXCF6MZDIJBBI6')"],"metadata":{"id":"43cnGzbcAsrV","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import anvil.server\n","\n","@anvil.server.callable\n","def Server(sentence):\n","    while True:\n","      #system_prompt = \" \"\n","      #eval_prompt = f\"{system_prompt} {user_input_prompt} #  Output \"\n","      eval_prompt = sentence\n","      model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","      ft_model.eval()\n","      with torch.no_grad():\n","          generated_tokens = ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.11)[0]\n","\n","      response = eval_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n","      last_full_stop_index = response.rfind('.')\n","      res = response[:last_full_stop_index + 1]\n","      return res\n","      break\n"],"metadata":{"id":"aOSmuy0rAxFk","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":8,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anvil.server.wait_forever()"],"metadata":{"id":"7zG50JCE3FqC","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take user input for the prompt\n","user_input_prompt = input(\"Enter your prompt: \")\n","\n","# Define the system prompt\n","system_prompt = \"Only give answers of the questions\"\n","\n","# Concatenate the system and user prompts\n","eval_prompt = f\"{system_prompt} {user_input_prompt} #  Output \"\n","\n","# Tokenize the prompt and move it to the GPU\n","model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","# Set the model to evaluation mode\n","ft_model.eval()\n","\n","# Generate a response\n","with torch.no_grad():\n","    generated_tokens = ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.11)[0]\n","\n","# Decode the generated tokens and skip special tokens\n","response = eval_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n","\n","last_full_stop_index = response.rfind('.')\n","\n","# Trim the text to include only up to the last full stop\n","res = response[:last_full_stop_index + 1]\n","\n","# Print the generated response\n","print(res)\n"],"metadata":{"id":"tQ8tDtqxor-C","executionInfo":{"status":"aborted","timestamp":1704287761008,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tushar Paul","userId":"07658428379744714472"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}